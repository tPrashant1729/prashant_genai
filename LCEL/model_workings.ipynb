{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "groq_api_key = os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(\n",
    "    model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=groq_api_key\n",
    "    # other params...\n",
    ")\n",
    "llm = chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I love programming in French is: \"J\\'aime programmer.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 30, 'total_tokens': 46, 'completion_time': 0.023908558, 'prompt_time': 0.002670042, 'queue_time': 0.010758778, 'total_time': 0.0265786}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c6999b9-005e-435a-9429-8c4b5ae30fc6-0', usage_metadata={'input_tokens': 30, 'output_tokens': 16, 'total_tokens': 46})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = chat.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "Up in the sky, in a world so new,\n",
      "There's a goldfish bowl, with a view.\n",
      "Swimming around, in weightless delight,\n",
      "In the moon's soft glow, through the endless night.\n",
      "\n",
      "(Chorus)\n",
      "Goldfish on the moon, in a silvery sea,\n",
      "Living their lives, so carefree.\n",
      "In a place we've only dreamed, they call it home,\n",
      "Oh, the tales they could tell, if they could only roam.\n",
      "\n",
      "(Verse 2)\n",
      "They dance with the stars, and play with the light,\n",
      "In their shimmering world, everything's just right.\n",
      "No predators here, no need to hide,\n",
      "Just a peaceful life, far and wide.\n",
      "\n",
      "(Chorus)\n",
      "Goldfish on the moon, in a crater so bright,\n",
      "Living their dreams, in the lunar night.\n",
      "In a place we've yet to tread, they've made their own,\n",
      "Oh, the secrets they keep, in their watery throne.\n",
      "\n",
      "(Bridge)\n",
      "In their silver castle, they twirl and they spin,\n",
      "In a world where no one else has ever been.\n",
      "A tiny piece of Earth, in the cosmic expanse,\n",
      "Home to these fish, with their heavenly dance.\n",
      "\n",
      "(Chorus)\n",
      "Goldfish on the moon, in a world so pure,\n",
      "Living their lives, with no impure.\n",
      "In a place we've yet to explore, they've made their own,\n",
      "Oh, the stories they'd tell, if they could only moan.\n",
      "\n",
      "(Outro)\n",
      "So here's to the goldfish, in their lunar home,\n",
      "Living their lives, all alone.\n",
      "In a place we've only dreamed, they've made it their own,\n",
      "Oh, the wonders they see, in their watery throne."
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream(\"Write me a song about goldfish on the moon\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_r9f4',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_pp8z',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wstx', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_9y1b', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_6vky', 'function': {'arguments': '{\"a\": 40, \"b\": 4}', 'name': 'divide'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 343, 'total_tokens': 436, 'completion_time': 0.08023527, 'prompt_time': 0.047237227, 'queue_time': 0.001767684999999998, 'total_time': 0.127472497}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7478c361-1885-424a-b642-5c6362e04d8d-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_wstx', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_9y1b', 'type': 'tool_call'}, {'name': 'divide', 'args': {'a': 40, 'b': 4}, 'id': 'call_6vky', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 93, 'total_tokens': 436})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[multiply(a=3, b=12), add(a=11, b=49)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[multiply, add])\n",
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
