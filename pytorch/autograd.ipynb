{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to snode (Python 3.10.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea8294-5c13-4976-8af6-8b93e23caf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "weights = t.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230884d4-edd3-40f3-9a47-9e62f5dd0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769755dd-f374-42ef-9b8f-0bcd9ff84efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([12., 12., 12., 12.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([15., 15., 15., 15.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([18., 18., 18., 18.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30566aad-92cf-4c77-8564-4edc45670411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    weights.grad.zero_()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146bc7a-6dbe-4e47-8d57-9b3bd31157bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4effb9-9bf0-4531-80e5-a4f9ecea2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428eedd-73fe-4717-82ec-aed56893a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680ca3e-dedc-4721-a0f6-ed96e61e4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "\n",
    "    print(weights.grad)\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d025bf3-80b2-4d35-b24b-18c468d0c361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "\n",
    "    print(weights.grad)\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf69ea-100d-4543-992f-b42cd4188678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'zero_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/dnk131/this_pc/code/prashant_genai/pytorch/autograd.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(weights\u001b[39m.\u001b[39mgrad)\n\u001b[0;32m----> 6\u001b[0m     weights\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mzero_()\n\u001b[1;32m      7\u001b[0m     model_op \u001b[39m=\u001b[39m (weights\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(model_op)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
     ]
    }
   ],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8952cb7-a264-470e-8566-5db1f2751aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'zero_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/home/dnk131/this_pc/code/prashant_genai/pytorch/autograd.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(model_op)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(weights\u001b[39m.\u001b[39mgrad)\n\u001b[0;32m----> 8\u001b[0m weights\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mzero_()\n\u001b[1;32m      9\u001b[0m model_op\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
     ]
    }
   ],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()\n",
    "    model_op.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9a49f-3761-4613-acc3-9d520473f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "\n",
    "    model_op = (weights*3).sum()\n",
    "    print(model_op)\n",
    "    model_op.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabe092-1745-493f-96fc-e5c3a4a11369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f058f24543da>:13: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(op_add.grad)\n",
      "<ipython-input-2-f058f24543da>:14: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(op_mean.grad)\n",
      "<ipython-input-2-f058f24543da>:15: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(model_op.grad)\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "weights = t.ones(2,3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "\n",
    "    model_op = weights*3\n",
    "    print(model_op)\n",
    "    op_mean = model_op.mean()\n",
    "    op_add= op_mean.add(4)\n",
    "    # weights.grad.zero_()\n",
    "    op_add.backward()\n",
    "    print(op_add.grad)\n",
    "    print(op_mean.grad)\n",
    "    print(model_op.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24afa80-2e33-46ba-a9b7-cbfa7c671c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5000, 3.5000, 3.5000],\n",
      "        [3.5000, 3.5000, 3.5000]])\n",
      "tensor([[4., 4., 4.],\n",
      "        [4., 4., 4.]])\n",
      "tensor([[4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "\n",
    "    model_op = weights*3\n",
    "    # print(model_op)\n",
    "    op_mean = model_op.mean()\n",
    "    op_add= op_mean.add(4)\n",
    "    # weights.grad.zero_()\n",
    "    op_add.backward()\n",
    "    # print(op_add.grad)\n",
    "    # print(op_mean.grad)\n",
    "    # print(model_op.grad)\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767321d0-1d3e-49ef-a8d2-d41b9da6f45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_add.grad: tensor(1.)\n",
      "op_mean.grad: tensor(1.)\n",
      "model_op.grad: tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n",
      "weights.grad: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "op_add.grad: tensor(1.)\n",
      "op_mean.grad: tensor(1.)\n",
      "model_op.grad: tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n",
      "weights.grad: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "op_add.grad: tensor(1.)\n",
      "op_mean.grad: tensor(1.)\n",
      "model_op.grad: tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n",
      "weights.grad: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "weights = t.ones(2, 3, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_op = (weights * 3)\n",
    "    model_op.retain_grad()  # Retain gradient for non-leaf node\n",
    "    op_mean = model_op.mean()\n",
    "    op_mean.retain_grad()  # Retain gradient for non-leaf node\n",
    "    op_add = op_mean.add(4)\n",
    "    op_add.retain_grad()  # Retain gradient for non-leaf node\n",
    "    \n",
    "    op_add.backward()\n",
    "    \n",
    "    print(\"op_add.grad:\", op_add.grad)\n",
    "    print(\"op_mean.grad:\", op_mean.grad)\n",
    "    print(\"model_op.grad:\", model_op.grad)\n",
    "    print(\"weights.grad:\", weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()  # Reset gradients for next epoch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
